{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy and inference Jina Reader LM with Azure app\n",
    "\n",
    "This notebook demonstrates how to deploy Jina Reader LM model-powered Azure managed application ([Reader-LM v2](https://azuremarketplace.microsoft.com/en-us/marketplace/apps/jinaai.reader-lm-v2?tab=Overview) \\ [Reader-LM 0.5b](https://azuremarketplace.microsoft.com/en-us/marketplace/apps/jinaai.reader-lm-500m?tab=Overview) \\ [Reader-LM 1.5b](https://azuremarketplace.microsoft.com/en-us/marketplace/apps/jinaai.reader-lm-1500m?tab=Overview)) and perform inference with this application.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the managed application\n",
    "\n",
    "To deploy your Azure managed application, start by consulting the [official deployment guide](https://learn.microsoft.com/en-us/azure/azure-resource-manager/managed-applications/deploy-marketplace-app-quickstart). This document provides comprehensive steps for the deployment process.\n",
    "\n",
    "It's worth mentioning that in the Basics tab of the deployment setup, you will need to provide several details about your deployment. \n",
    "\n",
    "You can customize the VM used, and for certain types, you might need to adjust the allowed quota to ensure access. It is recommended to use the [Standard_NC4as_T4_v3](https://learn.microsoft.com/en-us/azure/virtual-machines/nct4-v3-series) VM. This VM features up to 1 NVIDIA T4 GPU with 16 GB of memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/deploy_reader_app.png\" width=\"50%\" height=\"50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the deployment of the managed application is complete, proceed to the resource group created for your deployment (for instance, `mrg-vmgpu-20240920142516` as referenced in the provided screenshot) to verify the resources that have been established. \n",
    "\n",
    "Within this resource group, look for the `jina-inference-vm`. Here, you'll find the DNS Name through which you can access your application. In this example, the application is accessible via `testreader.eastus.cloudapp.azure.com`.\n",
    "\n",
    "Please note that the application will be unavailable immediately after deployment due to necessary post-deployment tasks such as driver installation, dependency setup, and system reboot. **We recommend waiting at least 15 minutes before using the application.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform inference with the managed application\n",
    "\n",
    "The Python example below demonstrates how to perform real-time inference using the public IP address of the deployed virtual machine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, construct the prompt using `create_prompt`, where you can specify the desired return format. This will improve the results according to specific scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt(text: str, return_type: str, instruction: str = None, schema: str = None):\n",
    "    \"\"\"\n",
    "    Creates a prompt based on the specified return type (either 'json' or 'markdown').\n",
    "    \n",
    "    Parameters:\n",
    "    - text (str): The HTML content that needs to be converted into the desired format.\n",
    "    - return_type (str): The desired return format. It must be either \"json\" or \"markdown\".\n",
    "    - instruction (str): The instruction to be included in the prompt. If not provided, a default instruction is used.\n",
    "    - schema (str): The JSON schema for structuring the output (used only for 'json' return_type). If empty, no schema is included.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    if return_type not in [\"json\", \"markdown\"]:\n",
    "        raise ValueError(\"Invalid return_type. Must be 'json' or 'markdown'.\")\n",
    "    \n",
    "    if return_type == \"json\":\n",
    "        if not instruction:\n",
    "            instruction = \"Extract the main content from the given HTML and convert it in a structured JSON format.\"\n",
    "\n",
    "        if schema:\n",
    "            prompt = f\"{instruction}\\n```html\\n{text}\\n```\\nThe JSON schema is as follows:```json{schema}```\" \n",
    "        else:\n",
    "            prompt = f\"{instruction}\\n```html\\n{text}\\n```\"\n",
    "    \n",
    "    elif return_type == \"markdown\":\n",
    "        if not instruction:\n",
    "            instruction = \"Extract the main content from the given HTML and convert it to Markdown format.\"\n",
    "        prompt = f\"{instruction}\\n```html\\n{text}\\n```\"\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "html = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html lang=\"en\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "    <title>Phone Book</title>\n",
    "</head>\n",
    "<body>\n",
    "    <h1>Phone Book</h1>\n",
    "    <div class=\"contact\">\n",
    "        <h2>John Doe</h2>\n",
    "        <p>Email: <a href=\"mailto:john.doe@example.com\">john.doe@example.com</a></p>\n",
    "    </div>\n",
    "    <div class=\"contact\">\n",
    "        <h2>Jane Smith</h2>\n",
    "        <p>Email: <a href=\"mailto:jane.smith@example.com\">jane.smith@example.com</a></p>\n",
    "    </div>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "prompt = create_prompt(return_type=\"markdown\", text=html)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then create the invoke function to execute inference, shown as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import requests\n",
    "\n",
    "\n",
    "def invoke_endpoint():\n",
    "    url = \"http://<Insert here your public IP address>/invocations\"  # With above example, it's \"http://20.84.48.180/invocations\"\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    json_data = {\n",
    "        \"model\": \"ReaderLM-v2\",  # If its Reader-LM 0.5b, please use \"reader-lm-0.5b\" as the model name, if it's Reader-LM 1.5b, please use \"reader-lm-1.5b\".\n",
    "        \"prompt\": prompt,\n",
    "        \"stream\": False  # Whether to stream back partial progress.\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, headers=headers, data=json.dumps(json_data))\n",
    "    print(response.json())\n",
    "\n",
    "\n",
    "invoke_endpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
