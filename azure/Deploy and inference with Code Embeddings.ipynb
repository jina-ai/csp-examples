{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy and inference Code Embeddings 0.5b/1.5b with Azure Virtual machine\n",
    "\n",
    "This notebook demonstrates how to deploy a [Jina Embeddings V4](https://jina.ai/news/jina-embeddings-v4-universal-embeddings-for-multimodal-multilingual-retrieval) model-powered [Azure Virtual machine](https://azuremarketplace.microsoft.com/en-us/marketplace/apps/jinaai.jina-embeddings-v4?tab=Overview) and perform inference with the application within the virtual machine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the virtual machine\n",
    "\n",
    "To deploy the virtual machine, start by consulting the [official deployment guide](https://learn.microsoft.com/en-us/azure/virtual-machines/windows/quick-create-portal). This document provides comprehensive steps for the deployment process.\n",
    "\n",
    "It's worth mentioning that in the Basics tab of the VM setup, you will need to provide several details about the VM. \n",
    "\n",
    "You can customize the VM size used, and for certain sizes, you might need to adjust the allowed quota to ensure access. It is recommended to use the [Standard_NC4as_T4_v3](https://learn.microsoft.com/en-us/azure/virtual-machines/nct4-v3-series) VM. This VM features up to 1 NVIDIA T4 GPU with 16 GB of memory.\n",
    "\n",
    "For the other tabs, you can leave most settings as default or adjust them to fit your needs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/deploy_embedding_v4.png\" width=\"50%\" height=\"50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the deployment of the VM is complete, proceed to the resource group created for your deployment to verify the resources that have been established. \n",
    "\n",
    "Within the resource group, you'll find the public IP through which you can access your application within the VM.\n",
    "\n",
    "Please note that the application within the VM will be unavailable immediately after deployment due to necessary model loading process **We recommend waiting at least 2 minutes before using the application.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform inference with the application\n",
    "\n",
    "The Python example below demonstrates how to perform real-time inference using the public IP address of the deployed virtual machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import requests\n",
    "\n",
    "\n",
    "def invoke_endpoint():\n",
    "    url = \"http://<Insert here your public IP address>/encode\"  # For example: http://20.84.48.180/encode\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    json_data = {\n",
    "        \"data\": [\n",
    "            {\n",
    "                \"text\": \"A beautiful sunset over the beach\"\n",
    "            },\n",
    "            {\n",
    "                \"text\": \"Un beau coucher de soleil sur la plage\"\n",
    "            },\n",
    "            {\n",
    "                \"text\": \"海滩上美丽的日落\"\n",
    "            },\n",
    "            {\n",
    "                \"text\": \"浜辺に沈む美しい夕日\"\n",
    "            },\n",
    "            {\n",
    "                \"image\": \"https://i.ibb.co/nQNGqL0/beach1.jpg\"\n",
    "            },\n",
    "            {\n",
    "                \"image\": \"https://i.ibb.co/r5w8hG8/beach2.jpg\"\n",
    "            },\n",
    "            {\n",
    "                \"image\": \"iVBORw0KGgoAAAANSUhEUgAAABwAAAA4CAIAAABhUg/jAAAAMklEQVR4nO3MQREAMAgAoLkoFreTiSzhy4MARGe9bX99lEqlUqlUKpVKpVKpVCqVHksHaBwCA2cPf0cAAAAASUVORK5CYII=\"\n",
    "            }\n",
    "    ]   ,\n",
    "        \"parameters\": {  # You can refer to https://jina.ai/news/jina-embeddings-v4-universal-embeddings-for-multimodal-multilingual-retrieval for details regarding the parameters.\n",
    "            \"task\": \"text-matching\",  # Select the downstream task for which the embeddings will be used. The model will return the optimized embeddings for that task. Should be one of `text-matching`, `retrieval.query`, `retrieval.passage`, `code.query`, or `code.passage`.\n",
    "            \"late_chunking\": False,  # Apply the late chunking technique to leverage the model's long-context capabilities for generating contextual chunk embeddings. Default to False.\n",
    "            \"dimensions\": 512,  # Output embedding size (128, 256, 512, 1025, 2048).\n",
    "            \"truncate\": False,  # Whether to truncate input text to the model's maximum length. Default to False.\n",
    "            \"return_multivector\": False,  # Whether to return multi-vector embeddings. Default to False.\n",
    "        } \n",
    "    }\n",
    "\n",
    "    response = requests.post(url, headers=headers, data=json.dumps(json_data))\n",
    "    print(response.json())\n",
    "\n",
    "\n",
    "invoke_endpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
