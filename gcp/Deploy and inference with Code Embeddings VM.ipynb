{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy and inference Jina Code Embeddings 0.5b/1.5b with Google Cloud Marketplace Virtual machine\n",
    "\n",
    "This notebook demonstrates how to deploy a Jina Code Embeddings model-powered [Google Cloud Marketplace Virtual machine (0.5b)](https://console.cloud.google.com/marketplace/product/jinaai-public/jina-code-embeddings-500m)/[Google Cloud Marketplace Virtual machine (1.5b)](https://console.cloud.google.com/marketplace/product/jinaai-public/jina-code-embeddings-1500m) and perform inference with the application within the virtual machine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the virtual machine\n",
    "\n",
    "To deploy the virtual machine, start by consulting the [official deployment guide](https://cloud.google.com/marketplace/docs/deploy-through-CLI#use-snippet). This document provides comprehensive steps for the deployment process.\n",
    "\n",
    "It's worth mentioning that in the Basics tab of the VM setup, you will need to provide several details about the VM. \n",
    "\n",
    "You can customize the VM size used, and for certain sizes, you might need to adjust the allowed quota to ensure access. It is recommended to select \"GPUs\" tab and use the [NVIDIA_L4](https://cloud.google.com/compute/docs/gpus?_gl=1*l4wato*_ga*MTI3NjQzMzcwNy4xNzI3NTg1MDYx*_ga_WH2QY8WWF5*MTczMDA4MDMzMC42NC4xLjE3MzAwODQ4NTQuMzcuMC4w#general_comparison_chart). This VM features up to 1 NVIDIA L4 GPU with 16 GB of memory. The boot disk size should be minimum 30 GB.\n",
    "\n",
    "For the other tabs, you can leave most settings as default or adjust them to fit your needs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/deploy_code_embeddings_vm.png\" width=\"50%\" height=\"50%\" style=\"max-width: 600px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the deployment of the VM is complete, proceed to the resource group created for your deployment to verify the resources that have been established. \n",
    "\n",
    "Within the resource group, you'll find the public IP through which you can access your application within the VM.\n",
    "\n",
    "Please note that the application within the VM will be unavailable immediately after deployment due to necessary model loading process **We recommend waiting at least 2 minutes before using the application.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform inference with the application\n",
    "\n",
    "The Python example below demonstrates how to perform real-time inference using the public IP address of the deployed virtual machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import requests\n",
    "\n",
    "\n",
    "def invoke_endpoint():\n",
    "    url = \"http://<Insert here your public IP address>/encode\"  # For example: http://20.84.48.180/encode\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    json_data = {\n",
    "        \"data\": [\n",
    "            \"Calculates the square of a number. Parameters: number (int or float) - The number to square. Returns: int or float - The square of the number.\",\n",
    "            \"This function calculates the square of a number you give it.\",\n",
    "            \"def square(number): return number ** 2\",\n",
    "            \"print(square(5))\",\n",
    "            \"Output: 25\",\n",
    "            \"Each text can be up to 8192 tokens long\"\n",
    "        ],\n",
    "        \"parameters\": {\n",
    "            # Select the downstream task for which the embeddings will be used.\n",
    "            # The model will return the optimized embeddings for that task.\n",
    "            # Options: nl2code.query, nl2code.passage, code2code.query, code2code.passage,\n",
    "            # code2nl.query, code2nl.passage, code2completion.query, code2completion.passage,\n",
    "            # qa.query, qa.passage\n",
    "            \"task\": \"nl2code.passage\"\n",
    "        } \n",
    "    }\n",
    "\n",
    "    response = requests.post(url, headers=headers, data=json.dumps(json_data))\n",
    "    print(response.json())\n",
    "\n",
    "\n",
    "invoke_endpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
